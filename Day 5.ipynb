{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Numpy - numerical manipulation\n",
    "import numpy as np\n",
    "\n",
    "# Pandas - data I/O, dataset maninpultion\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# Scikit-Learn - easy ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Matplotlib - visualization\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "from plot_util import get_colormap\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_tr, y_tr), (X_te, y_te) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, dtype('float32'), (60000, 28, 28))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_tr), X_tr.dtype, X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (60000,), array([5], dtype=uint8))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_tr), y_tr.shape, y_tr[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = X_tr.astype('float32')\n",
    "X_te = X_te.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr.max(), X_tr.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X: 2D --> 1D\n",
    "X_tr = X_tr.reshape(60000, 28*28)\n",
    "X_te = X_te.reshape(10000, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsca_tr = scaler.fit_transform(X_tr)\n",
    "Xsca_te = scaler.fit_transform(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y: one-hot encoding (y -> Y)\n",
    "from keras.utils import np_utils\n",
    "\n",
    "Y_tr = np_utils.to_categorical(y_tr)\n",
    "Y_te = np_utils.to_categorical(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model selection\n",
    "\n",
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense\n",
    "\n",
    "layer = Dense(10, input_shape=(784,), activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='sgd',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 4.7038 - acc: 0.5397 - val_loss: 2.2885 - val_acc: 0.7232\n",
      "Epoch 2/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 1.6522 - acc: 0.7812 - val_loss: 1.0753 - val_acc: 0.8350\n",
      "Epoch 3/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 1.0054 - acc: 0.8435 - val_loss: 0.7925 - val_acc: 0.8650\n",
      "Epoch 4/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.7710 - acc: 0.8677 - val_loss: 0.6562 - val_acc: 0.8814\n",
      "Epoch 5/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.6542 - acc: 0.8813 - val_loss: 0.5864 - val_acc: 0.8902\n",
      "Epoch 6/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.5898 - acc: 0.8896 - val_loss: 0.5457 - val_acc: 0.8959\n",
      "Epoch 7/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.5479 - acc: 0.8946 - val_loss: 0.5176 - val_acc: 0.8997\n",
      "Epoch 8/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.5162 - acc: 0.8987 - val_loss: 0.4960 - val_acc: 0.9026\n",
      "Epoch 9/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.4911 - acc: 0.9020 - val_loss: 0.4790 - val_acc: 0.9055\n",
      "Epoch 10/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.4702 - acc: 0.9046 - val_loss: 0.4639 - val_acc: 0.9072\n",
      "Epoch 11/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.4524 - acc: 0.9070 - val_loss: 0.4514 - val_acc: 0.9094\n",
      "Epoch 12/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.4370 - acc: 0.9090 - val_loss: 0.4405 - val_acc: 0.9103\n",
      "Epoch 13/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.4233 - acc: 0.9107 - val_loss: 0.4305 - val_acc: 0.9111\n",
      "Epoch 14/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.4112 - acc: 0.9119 - val_loss: 0.4219 - val_acc: 0.9121\n",
      "Epoch 15/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.4001 - acc: 0.9131 - val_loss: 0.4144 - val_acc: 0.9128\n",
      "Epoch 16/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3900 - acc: 0.9146 - val_loss: 0.4076 - val_acc: 0.9136\n",
      "Epoch 17/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3814 - acc: 0.9156 - val_loss: 0.4005 - val_acc: 0.9147\n",
      "Epoch 18/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3737 - acc: 0.9165 - val_loss: 0.3952 - val_acc: 0.9143\n",
      "Epoch 19/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3665 - acc: 0.9172 - val_loss: 0.3893 - val_acc: 0.9158\n",
      "Epoch 20/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.3600 - acc: 0.9180 - val_loss: 0.3850 - val_acc: 0.9158\n",
      "Epoch 21/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3542 - acc: 0.9192 - val_loss: 0.3801 - val_acc: 0.9158\n",
      "Epoch 22/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3489 - acc: 0.9196 - val_loss: 0.3756 - val_acc: 0.9173\n",
      "Epoch 23/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3438 - acc: 0.9208 - val_loss: 0.3719 - val_acc: 0.9173\n",
      "Epoch 24/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3393 - acc: 0.9213 - val_loss: 0.3682 - val_acc: 0.9170\n",
      "Epoch 25/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3349 - acc: 0.9216 - val_loss: 0.3647 - val_acc: 0.9179\n",
      "Epoch 26/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3309 - acc: 0.9220 - val_loss: 0.3615 - val_acc: 0.9179\n",
      "Epoch 27/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3271 - acc: 0.9230 - val_loss: 0.3585 - val_acc: 0.9180\n",
      "Epoch 28/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3236 - acc: 0.9231 - val_loss: 0.3552 - val_acc: 0.9186\n",
      "Epoch 29/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3202 - acc: 0.9238 - val_loss: 0.3531 - val_acc: 0.9187\n",
      "Epoch 30/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3171 - acc: 0.9242 - val_loss: 0.3504 - val_acc: 0.9193\n",
      "Epoch 31/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3140 - acc: 0.9244 - val_loss: 0.3480 - val_acc: 0.9190\n",
      "Epoch 32/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.3111 - acc: 0.9249 - val_loss: 0.3459 - val_acc: 0.9200\n",
      "Epoch 33/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3085 - acc: 0.9252 - val_loss: 0.3433 - val_acc: 0.9204\n",
      "Epoch 34/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.3059 - acc: 0.9260 - val_loss: 0.3413 - val_acc: 0.9203\n",
      "Epoch 35/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3034 - acc: 0.9260 - val_loss: 0.3395 - val_acc: 0.9207\n",
      "Epoch 36/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3011 - acc: 0.9265 - val_loss: 0.3373 - val_acc: 0.9207\n",
      "Epoch 37/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2990 - acc: 0.9267 - val_loss: 0.3355 - val_acc: 0.9207\n",
      "Epoch 38/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2968 - acc: 0.9271 - val_loss: 0.3341 - val_acc: 0.9208\n",
      "Epoch 39/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2948 - acc: 0.9272 - val_loss: 0.3324 - val_acc: 0.9207\n",
      "Epoch 40/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2928 - acc: 0.9275 - val_loss: 0.3306 - val_acc: 0.9216\n",
      "Epoch 41/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2911 - acc: 0.9277 - val_loss: 0.3290 - val_acc: 0.9214\n",
      "Epoch 42/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2892 - acc: 0.9284 - val_loss: 0.3275 - val_acc: 0.9211\n",
      "Epoch 43/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2875 - acc: 0.9281 - val_loss: 0.3262 - val_acc: 0.9213\n",
      "Epoch 44/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2859 - acc: 0.9287 - val_loss: 0.3253 - val_acc: 0.9212\n",
      "Epoch 45/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2843 - acc: 0.9288 - val_loss: 0.3240 - val_acc: 0.9215\n",
      "Epoch 46/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2828 - acc: 0.9292 - val_loss: 0.3226 - val_acc: 0.9217\n",
      "Epoch 47/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2814 - acc: 0.9293 - val_loss: 0.3214 - val_acc: 0.9218\n",
      "Epoch 48/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2799 - acc: 0.9295 - val_loss: 0.3205 - val_acc: 0.9218\n",
      "Epoch 49/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2787 - acc: 0.9301 - val_loss: 0.3192 - val_acc: 0.9225\n",
      "Epoch 50/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2774 - acc: 0.9295 - val_loss: 0.3183 - val_acc: 0.9229\n",
      "Epoch 51/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2762 - acc: 0.9305 - val_loss: 0.3176 - val_acc: 0.9225\n",
      "Epoch 52/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2750 - acc: 0.9302 - val_loss: 0.3163 - val_acc: 0.9228\n",
      "Epoch 53/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2738 - acc: 0.9304 - val_loss: 0.3156 - val_acc: 0.9236\n",
      "Epoch 54/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2728 - acc: 0.9306 - val_loss: 0.3148 - val_acc: 0.9237\n",
      "Epoch 55/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2717 - acc: 0.9308 - val_loss: 0.3139 - val_acc: 0.9233\n",
      "Epoch 56/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2706 - acc: 0.9306 - val_loss: 0.3129 - val_acc: 0.9233\n",
      "Epoch 57/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2697 - acc: 0.9310 - val_loss: 0.3120 - val_acc: 0.9235\n",
      "Epoch 58/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2688 - acc: 0.9314 - val_loss: 0.3113 - val_acc: 0.9235\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2678 - acc: 0.9314 - val_loss: 0.3108 - val_acc: 0.9236\n",
      "Epoch 60/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2669 - acc: 0.9314 - val_loss: 0.3099 - val_acc: 0.9235\n",
      "Epoch 61/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2661 - acc: 0.9317 - val_loss: 0.3094 - val_acc: 0.9236\n",
      "Epoch 62/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2653 - acc: 0.9318 - val_loss: 0.3088 - val_acc: 0.9238\n",
      "Epoch 63/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2644 - acc: 0.9314 - val_loss: 0.3085 - val_acc: 0.9235\n",
      "Epoch 64/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2637 - acc: 0.9317 - val_loss: 0.3079 - val_acc: 0.9238\n",
      "Epoch 65/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2629 - acc: 0.9320 - val_loss: 0.3070 - val_acc: 0.9240\n",
      "Epoch 66/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2622 - acc: 0.9322 - val_loss: 0.3072 - val_acc: 0.9233\n",
      "Epoch 67/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2615 - acc: 0.9326 - val_loss: 0.3063 - val_acc: 0.9236\n",
      "Epoch 68/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2607 - acc: 0.9322 - val_loss: 0.3058 - val_acc: 0.9238\n",
      "Epoch 69/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2601 - acc: 0.9327 - val_loss: 0.3049 - val_acc: 0.9252\n",
      "Epoch 70/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2595 - acc: 0.9324 - val_loss: 0.3046 - val_acc: 0.9245\n",
      "Epoch 71/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2589 - acc: 0.9327 - val_loss: 0.3043 - val_acc: 0.9245\n",
      "Epoch 72/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2582 - acc: 0.9328 - val_loss: 0.3038 - val_acc: 0.9251\n",
      "Epoch 73/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2576 - acc: 0.9330 - val_loss: 0.3034 - val_acc: 0.9252\n",
      "Epoch 74/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2571 - acc: 0.9329 - val_loss: 0.3032 - val_acc: 0.9248\n",
      "Epoch 75/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2565 - acc: 0.9331 - val_loss: 0.3031 - val_acc: 0.9251\n",
      "Epoch 76/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2560 - acc: 0.9330 - val_loss: 0.3025 - val_acc: 0.9247\n",
      "Epoch 77/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2554 - acc: 0.9327 - val_loss: 0.3022 - val_acc: 0.9254\n",
      "Epoch 78/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2549 - acc: 0.9334 - val_loss: 0.3017 - val_acc: 0.9254\n",
      "Epoch 79/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2544 - acc: 0.9336 - val_loss: 0.3012 - val_acc: 0.9253\n",
      "Epoch 80/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2539 - acc: 0.9332 - val_loss: 0.3010 - val_acc: 0.9253\n",
      "Epoch 81/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2534 - acc: 0.9336 - val_loss: 0.3007 - val_acc: 0.9252\n",
      "Epoch 82/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2529 - acc: 0.9336 - val_loss: 0.3005 - val_acc: 0.9250\n",
      "Epoch 83/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2525 - acc: 0.9336 - val_loss: 0.3002 - val_acc: 0.9258\n",
      "Epoch 84/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2521 - acc: 0.9335 - val_loss: 0.2999 - val_acc: 0.9251\n",
      "Epoch 85/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2515 - acc: 0.9336 - val_loss: 0.2993 - val_acc: 0.9253\n",
      "Epoch 86/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2512 - acc: 0.9338 - val_loss: 0.2994 - val_acc: 0.9252\n",
      "Epoch 87/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2508 - acc: 0.9340 - val_loss: 0.2991 - val_acc: 0.9251\n",
      "Epoch 88/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2504 - acc: 0.9343 - val_loss: 0.2992 - val_acc: 0.9256\n",
      "Epoch 89/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2500 - acc: 0.9339 - val_loss: 0.2986 - val_acc: 0.9260\n",
      "Epoch 90/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2496 - acc: 0.9341 - val_loss: 0.2986 - val_acc: 0.9262\n",
      "Epoch 91/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2492 - acc: 0.9341 - val_loss: 0.2983 - val_acc: 0.9256\n",
      "Epoch 92/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2488 - acc: 0.9344 - val_loss: 0.2978 - val_acc: 0.9258\n",
      "Epoch 93/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2484 - acc: 0.9344 - val_loss: 0.2980 - val_acc: 0.9257\n",
      "Epoch 94/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2481 - acc: 0.9344 - val_loss: 0.2972 - val_acc: 0.9263\n",
      "Epoch 95/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2478 - acc: 0.9346 - val_loss: 0.2974 - val_acc: 0.9258\n",
      "Epoch 96/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2474 - acc: 0.9346 - val_loss: 0.2974 - val_acc: 0.9262\n",
      "Epoch 97/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2470 - acc: 0.9347 - val_loss: 0.2967 - val_acc: 0.9257\n",
      "Epoch 98/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2467 - acc: 0.9346 - val_loss: 0.2966 - val_acc: 0.9263\n",
      "Epoch 99/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2464 - acc: 0.9349 - val_loss: 0.2968 - val_acc: 0.9257\n",
      "Epoch 100/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2461 - acc: 0.9349 - val_loss: 0.2967 - val_acc: 0.9260\n",
      "Epoch 101/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2458 - acc: 0.9350 - val_loss: 0.2966 - val_acc: 0.9260\n",
      "Epoch 102/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2454 - acc: 0.9349 - val_loss: 0.2961 - val_acc: 0.9265\n",
      "Epoch 103/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2451 - acc: 0.9351 - val_loss: 0.2963 - val_acc: 0.9260\n",
      "Epoch 104/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2449 - acc: 0.9354 - val_loss: 0.2959 - val_acc: 0.9257\n",
      "Epoch 105/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2446 - acc: 0.9351 - val_loss: 0.2956 - val_acc: 0.9263\n",
      "Epoch 106/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2442 - acc: 0.9349 - val_loss: 0.2953 - val_acc: 0.9264\n",
      "Epoch 107/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2440 - acc: 0.9354 - val_loss: 0.2950 - val_acc: 0.9266\n",
      "Epoch 108/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2437 - acc: 0.9353 - val_loss: 0.2951 - val_acc: 0.9258\n",
      "Epoch 109/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2435 - acc: 0.9353 - val_loss: 0.2950 - val_acc: 0.9260\n",
      "Epoch 110/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2431 - acc: 0.9354 - val_loss: 0.2950 - val_acc: 0.9259\n",
      "Epoch 111/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2429 - acc: 0.9355 - val_loss: 0.2945 - val_acc: 0.9262\n",
      "Epoch 112/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2426 - acc: 0.9354 - val_loss: 0.2943 - val_acc: 0.9260\n",
      "Epoch 113/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2423 - acc: 0.9350 - val_loss: 0.2944 - val_acc: 0.9258\n",
      "Epoch 114/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2421 - acc: 0.9355 - val_loss: 0.2940 - val_acc: 0.9258\n",
      "Epoch 115/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2418 - acc: 0.9354 - val_loss: 0.2940 - val_acc: 0.9261\n",
      "Epoch 116/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2415 - acc: 0.9356 - val_loss: 0.2941 - val_acc: 0.9259\n",
      "Epoch 117/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2413 - acc: 0.9353 - val_loss: 0.2937 - val_acc: 0.9262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2411 - acc: 0.9354 - val_loss: 0.2937 - val_acc: 0.9262\n",
      "Epoch 119/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2409 - acc: 0.9355 - val_loss: 0.2937 - val_acc: 0.9259\n",
      "Epoch 120/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2406 - acc: 0.9354 - val_loss: 0.2932 - val_acc: 0.9262\n",
      "Epoch 121/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2404 - acc: 0.9354 - val_loss: 0.2933 - val_acc: 0.9263\n",
      "Epoch 122/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2402 - acc: 0.9357 - val_loss: 0.2933 - val_acc: 0.9258\n",
      "Epoch 123/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2399 - acc: 0.9360 - val_loss: 0.2930 - val_acc: 0.9258\n",
      "Epoch 124/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2398 - acc: 0.9358 - val_loss: 0.2928 - val_acc: 0.9267\n",
      "Epoch 125/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2395 - acc: 0.9359 - val_loss: 0.2932 - val_acc: 0.9265\n",
      "Epoch 126/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2393 - acc: 0.9359 - val_loss: 0.2931 - val_acc: 0.9257\n",
      "Epoch 127/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2392 - acc: 0.9352 - val_loss: 0.2926 - val_acc: 0.9264\n",
      "Epoch 128/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2389 - acc: 0.9362 - val_loss: 0.2925 - val_acc: 0.9262\n",
      "Epoch 129/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2388 - acc: 0.9360 - val_loss: 0.2923 - val_acc: 0.9262\n",
      "Epoch 130/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2386 - acc: 0.9363 - val_loss: 0.2928 - val_acc: 0.9259\n",
      "Epoch 131/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2384 - acc: 0.9360 - val_loss: 0.2925 - val_acc: 0.9262\n",
      "Epoch 132/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2382 - acc: 0.9364 - val_loss: 0.2920 - val_acc: 0.9265\n",
      "Epoch 133/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2380 - acc: 0.9362 - val_loss: 0.2922 - val_acc: 0.9265\n",
      "Epoch 134/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2378 - acc: 0.9361 - val_loss: 0.2922 - val_acc: 0.9268\n",
      "Epoch 135/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2376 - acc: 0.9363 - val_loss: 0.2923 - val_acc: 0.9263\n",
      "Epoch 136/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2374 - acc: 0.9364 - val_loss: 0.2921 - val_acc: 0.9261\n",
      "Epoch 137/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2373 - acc: 0.9363 - val_loss: 0.2918 - val_acc: 0.9267\n",
      "Epoch 138/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2371 - acc: 0.9364 - val_loss: 0.2921 - val_acc: 0.9262\n",
      "Epoch 139/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2369 - acc: 0.9364 - val_loss: 0.2922 - val_acc: 0.9267\n",
      "Epoch 140/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2368 - acc: 0.9364 - val_loss: 0.2916 - val_acc: 0.9262\n",
      "Epoch 141/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2366 - acc: 0.9362 - val_loss: 0.2922 - val_acc: 0.9261\n",
      "Epoch 142/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2364 - acc: 0.9365 - val_loss: 0.2919 - val_acc: 0.9261\n",
      "Epoch 143/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2362 - acc: 0.9368 - val_loss: 0.2919 - val_acc: 0.9263\n",
      "Epoch 144/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2361 - acc: 0.9364 - val_loss: 0.2921 - val_acc: 0.9262\n",
      "Epoch 145/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2359 - acc: 0.9368 - val_loss: 0.2918 - val_acc: 0.9262\n",
      "Epoch 146/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2358 - acc: 0.9368 - val_loss: 0.2913 - val_acc: 0.9266\n",
      "Epoch 147/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2356 - acc: 0.9370 - val_loss: 0.2912 - val_acc: 0.9265\n",
      "Epoch 148/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2355 - acc: 0.9368 - val_loss: 0.2913 - val_acc: 0.9266\n",
      "Epoch 149/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2353 - acc: 0.9369 - val_loss: 0.2914 - val_acc: 0.9263\n",
      "Epoch 150/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2352 - acc: 0.9371 - val_loss: 0.2914 - val_acc: 0.9263\n",
      "Epoch 151/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2350 - acc: 0.9365 - val_loss: 0.2912 - val_acc: 0.9265\n",
      "Epoch 152/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2348 - acc: 0.9365 - val_loss: 0.2909 - val_acc: 0.9266\n",
      "Epoch 153/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2347 - acc: 0.9370 - val_loss: 0.2911 - val_acc: 0.9267\n",
      "Epoch 154/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2346 - acc: 0.9369 - val_loss: 0.2911 - val_acc: 0.9263\n",
      "Epoch 155/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2344 - acc: 0.9370 - val_loss: 0.2909 - val_acc: 0.9264\n",
      "Epoch 156/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2343 - acc: 0.9371 - val_loss: 0.2909 - val_acc: 0.9267\n",
      "Epoch 157/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2341 - acc: 0.9373 - val_loss: 0.2910 - val_acc: 0.9264\n",
      "Epoch 158/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2339 - acc: 0.9372 - val_loss: 0.2909 - val_acc: 0.9269\n",
      "Epoch 159/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2339 - acc: 0.9370 - val_loss: 0.2908 - val_acc: 0.9263\n",
      "Epoch 160/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2337 - acc: 0.9374 - val_loss: 0.2910 - val_acc: 0.9267\n",
      "Epoch 161/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2336 - acc: 0.9371 - val_loss: 0.2913 - val_acc: 0.9260\n",
      "Epoch 162/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2335 - acc: 0.9372 - val_loss: 0.2912 - val_acc: 0.9262\n",
      "Epoch 163/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2333 - acc: 0.9374 - val_loss: 0.2906 - val_acc: 0.9265\n",
      "Epoch 164/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2332 - acc: 0.9375 - val_loss: 0.2906 - val_acc: 0.9267\n",
      "Epoch 165/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2330 - acc: 0.9373 - val_loss: 0.2910 - val_acc: 0.9271\n",
      "Epoch 166/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2329 - acc: 0.9375 - val_loss: 0.2907 - val_acc: 0.9265\n",
      "Epoch 167/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2329 - acc: 0.9372 - val_loss: 0.2907 - val_acc: 0.9267\n",
      "Epoch 168/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2327 - acc: 0.9376 - val_loss: 0.2910 - val_acc: 0.9263\n",
      "Epoch 169/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2326 - acc: 0.9378 - val_loss: 0.2905 - val_acc: 0.9269\n",
      "Epoch 170/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2324 - acc: 0.9374 - val_loss: 0.2908 - val_acc: 0.9266\n",
      "Epoch 171/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2323 - acc: 0.9376 - val_loss: 0.2905 - val_acc: 0.9265\n",
      "Epoch 172/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2322 - acc: 0.9375 - val_loss: 0.2904 - val_acc: 0.9265\n",
      "Epoch 173/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2317 - acc: 0.9378 - val_loss: 0.2906 - val_acc: 0.9264\n",
      "Epoch 174/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2317 - acc: 0.9374 - val_loss: 0.2901 - val_acc: 0.9267\n",
      "Epoch 175/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2315 - acc: 0.9374 - val_loss: 0.2899 - val_acc: 0.9267\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2314 - acc: 0.9379 - val_loss: 0.2904 - val_acc: 0.9263\n",
      "Epoch 177/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2313 - acc: 0.9379 - val_loss: 0.2902 - val_acc: 0.9267\n",
      "Epoch 178/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2311 - acc: 0.9379 - val_loss: 0.2904 - val_acc: 0.9263\n",
      "Epoch 179/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2311 - acc: 0.9375 - val_loss: 0.2903 - val_acc: 0.9269\n",
      "Epoch 180/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2310 - acc: 0.9377 - val_loss: 0.2900 - val_acc: 0.9267\n",
      "Epoch 181/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2308 - acc: 0.9377 - val_loss: 0.2901 - val_acc: 0.9266\n",
      "Epoch 182/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2307 - acc: 0.9379 - val_loss: 0.2903 - val_acc: 0.9264\n",
      "Epoch 183/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2305 - acc: 0.9380 - val_loss: 0.2902 - val_acc: 0.9269\n",
      "Epoch 184/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2305 - acc: 0.9379 - val_loss: 0.2901 - val_acc: 0.9271\n",
      "Epoch 185/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2304 - acc: 0.9379 - val_loss: 0.2898 - val_acc: 0.9272\n",
      "Epoch 186/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2303 - acc: 0.9381 - val_loss: 0.2903 - val_acc: 0.9267\n",
      "Epoch 187/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2302 - acc: 0.9378 - val_loss: 0.2901 - val_acc: 0.9272\n",
      "Epoch 188/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2301 - acc: 0.9382 - val_loss: 0.2900 - val_acc: 0.9272\n",
      "Epoch 189/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2300 - acc: 0.9382 - val_loss: 0.2899 - val_acc: 0.9267\n",
      "Epoch 190/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2299 - acc: 0.9381 - val_loss: 0.2900 - val_acc: 0.9268\n",
      "Epoch 191/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2298 - acc: 0.9381 - val_loss: 0.2899 - val_acc: 0.9272\n",
      "Epoch 192/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2297 - acc: 0.9381 - val_loss: 0.2901 - val_acc: 0.9272\n",
      "Epoch 193/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2295 - acc: 0.9382 - val_loss: 0.2899 - val_acc: 0.9268\n",
      "Epoch 194/200\n",
      "48000/48000 [==============================] - 1s 11us/step - loss: 0.2295 - acc: 0.9379 - val_loss: 0.2900 - val_acc: 0.9275\n",
      "Epoch 195/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2293 - acc: 0.9388 - val_loss: 0.2902 - val_acc: 0.9267\n",
      "Epoch 196/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2292 - acc: 0.9381 - val_loss: 0.2901 - val_acc: 0.9268\n",
      "Epoch 197/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2292 - acc: 0.9383 - val_loss: 0.2898 - val_acc: 0.9273\n",
      "Epoch 198/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2291 - acc: 0.9385 - val_loss: 0.2900 - val_acc: 0.9269\n",
      "Epoch 199/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2289 - acc: 0.9384 - val_loss: 0.2899 - val_acc: 0.9268\n",
      "Epoch 200/200\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.2289 - acc: 0.9383 - val_loss: 0.2898 - val_acc: 0.9267\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(Xsca_tr, Y_tr, batch_size=128, epochs=200, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.539687</td>\n",
       "      <td>4.703822</td>\n",
       "      <td>0.723250</td>\n",
       "      <td>2.288533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.781229</td>\n",
       "      <td>1.652187</td>\n",
       "      <td>0.835000</td>\n",
       "      <td>1.075295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.843500</td>\n",
       "      <td>1.005381</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.792515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.867687</td>\n",
       "      <td>0.770974</td>\n",
       "      <td>0.881417</td>\n",
       "      <td>0.656183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.881333</td>\n",
       "      <td>0.654189</td>\n",
       "      <td>0.890167</td>\n",
       "      <td>0.586406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc      loss   val_acc  val_loss\n",
       "0  0.539687  4.703822  0.723250  2.288533\n",
       "1  0.781229  1.652187  0.835000  1.075295\n",
       "2  0.843500  1.005381  0.865000  0.792515\n",
       "3  0.867687  0.770974  0.881417  0.656183\n",
       "4  0.881333  0.654189  0.890167  0.586406"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_result = DataFrame(history.history)\n",
    "tr_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14859e48>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD7CAYAAABkO19ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x148655c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_result[['acc', 'val_acc']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14929240>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAD7CAYAAAChScXIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEUkQJW0RkQRR0hYRSRAlbRGRBPn/1hlyDSRHkrUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14934c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_result[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 17us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(Xsca_te, Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.300, Acc: 92.57%\n"
     ]
    }
   ],
   "source": [
    "print('Loss: {:.3f}, Acc: {:.2%}'.format(*score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 134,794\n",
      "Trainable params: 134,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(784,), activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x152196d8>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD7CAYAAABkO19ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x151ad080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-0.5, 0.5, 0.1)\n",
    "plt.plot(x, relu(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='sgd',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 1.1383 - acc: 0.6930 - val_loss: 0.5081 - val_acc: 0.8650\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.4092 - acc: 0.8845 - val_loss: 0.3287 - val_acc: 0.9075\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.3036 - acc: 0.9122 - val_loss: 0.2735 - val_acc: 0.9222\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.2545 - acc: 0.9255 - val_loss: 0.2425 - val_acc: 0.9312\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.2227 - acc: 0.9346 - val_loss: 0.2218 - val_acc: 0.9373\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1996 - acc: 0.9416 - val_loss: 0.2077 - val_acc: 0.9423\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1816 - acc: 0.9467 - val_loss: 0.1948 - val_acc: 0.9451\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1666 - acc: 0.9512 - val_loss: 0.1859 - val_acc: 0.9489\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1546 - acc: 0.9552 - val_loss: 0.1783 - val_acc: 0.9506\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1439 - acc: 0.9583 - val_loss: 0.1734 - val_acc: 0.9529\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1349 - acc: 0.9610 - val_loss: 0.1688 - val_acc: 0.9529\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1267 - acc: 0.9637 - val_loss: 0.1635 - val_acc: 0.9557\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1195 - acc: 0.9659 - val_loss: 0.1604 - val_acc: 0.9569\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1128 - acc: 0.9680 - val_loss: 0.1565 - val_acc: 0.9584\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1068 - acc: 0.9697 - val_loss: 0.1539 - val_acc: 0.9584\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1011 - acc: 0.9716 - val_loss: 0.1517 - val_acc: 0.9598\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0961 - acc: 0.9733 - val_loss: 0.1488 - val_acc: 0.9601\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0914 - acc: 0.9749 - val_loss: 0.1473 - val_acc: 0.9607\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0869 - acc: 0.9764 - val_loss: 0.1453 - val_acc: 0.9607\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0826 - acc: 0.9772 - val_loss: 0.1447 - val_acc: 0.9613\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(Xsca_tr, Y_tr, batch_size=128, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(score):\n",
    "    print('Loss: {:.3f}, Acc.: {:.2%}'.format(*score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 24us/step\n",
      "Loss: 0.140, Acc.: 95.96%\n"
     ]
    }
   ],
   "source": [
    "print_score(model.evaluate(Xsca_te, Y_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 2D (reshape)\n",
    "\n",
    "Xsca_tr = Xsca_tr.reshape(60000, 28, 28)\n",
    "Xsca_te = Xsca_te.reshape(10000, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(Xsca_tr, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Add channel\n",
    "Xsca_tr = np.expand_dims(Xsca_tr, -1)\n",
    "Xsca_te = np.expand_dims(Xsca_te, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## setup model\n",
    "cnn_model = Sequential()\n",
    "\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model.add(Conv2D(20,\n",
    "                    kernel_size=5, padding='same',\n",
    "                    input_shape=(28, 28, 1), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model.add(Conv2D(50,\n",
    "                    kernel_size=5, padding='same', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Fully Connected Layer (FC)\n",
    "from keras.layers.core import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(500, activation='relu'))\n",
    "cnn_model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 50s 1ms/step - loss: 0.1360 - acc: 0.9683 - val_loss: 0.0642 - val_acc: 0.9820\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0486 - acc: 0.9854 - val_loss: 0.0547 - val_acc: 0.9843\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0386 - acc: 0.9883 - val_loss: 0.0587 - val_acc: 0.9840\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0265 - acc: 0.9919 - val_loss: 0.0416 - val_acc: 0.9888\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0181 - acc: 0.9939 - val_loss: 0.0513 - val_acc: 0.9865\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0191 - acc: 0.9937 - val_loss: 0.0417 - val_acc: 0.9897\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0151 - acc: 0.9955 - val_loss: 0.0451 - val_acc: 0.9878\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0107 - acc: 0.9965 - val_loss: 0.0616 - val_acc: 0.9862\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0109 - acc: 0.9966 - val_loss: 0.0507 - val_acc: 0.9877\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 49s 1ms/step - loss: 0.0120 - acc: 0.9965 - val_loss: 0.0549 - val_acc: 0.9871\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 49s 1ms/step - loss: 0.0131 - acc: 0.9957 - val_loss: 0.0442 - val_acc: 0.9904\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0086 - acc: 0.9972 - val_loss: 0.0459 - val_acc: 0.9882\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0077 - acc: 0.9976 - val_loss: 0.0590 - val_acc: 0.9875\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0072 - acc: 0.9978 - val_loss: 0.0516 - val_acc: 0.9898\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0089 - acc: 0.9971 - val_loss: 0.0562 - val_acc: 0.9893\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0688 - val_acc: 0.9867\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0105 - acc: 0.9973 - val_loss: 0.0520 - val_acc: 0.9885\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0053 - acc: 0.9981 - val_loss: 0.0557 - val_acc: 0.9892\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0034 - acc: 0.9990 - val_loss: 0.0582 - val_acc: 0.9901\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 50s 1ms/step - loss: 0.0020 - acc: 0.9992 - val_loss: 0.0600 - val_acc: 0.9903\n"
     ]
    }
   ],
   "source": [
    "cnn_history = cnn_model.fit(Xsca_tr, Y_tr, batch_size=128, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 20)        520       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 50)        25050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2450)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 500)               1225500   \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 1,256,080\n",
      "Trainable params: 1,256,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 384us/step\n",
      "Loss: 0.040, Acc.: 99.14%\n"
     ]
    }
   ],
   "source": [
    "print_score(cnn_model.evaluate(Xsca_te, Y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save('cnn_model.sav')\n",
    "cnn_model.save_weights('cnn_model_weight.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasetstasetstasetstasetstasetstasetstasetstasetsdatasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 218s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(X_tr, y_tr), (X_te, y_te) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr = X_tr.astype('float32')\n",
    "X_te = X_te.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr /= X_tr.max()\n",
    "X_te /= X_te.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_tr = np_utils.to_categorical(y_tr)\n",
    "Y_te = np_utils.to_categorical(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_model = Sequential()\n",
    "\n",
    "cifar_model.add(Conv2D(32, kernel_size=(3,3), padding='same',\n",
    "                       input_shape=(32, 32, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cifar_model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar_model.add(Flatten())\n",
    "cifar_model.add(Dense(512, activation='relu'))\n",
    "cifar_model.add(Dropout(0.5))\n",
    "cifar_model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_model.compile(loss='categorical_crossentropy',\n",
    "                   optimizer='adam',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 31s 773us/step - loss: 1.6390 - acc: 0.4114 - val_loss: 1.3871 - val_acc: 0.5141\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 30s 758us/step - loss: 1.3411 - acc: 0.5238 - val_loss: 1.2211 - val_acc: 0.5796\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 30s 759us/step - loss: 1.2508 - acc: 0.5570 - val_loss: 1.1506 - val_acc: 0.6087\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 30s 755us/step - loss: 1.1925 - acc: 0.5759 - val_loss: 1.1029 - val_acc: 0.6192\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 30s 758us/step - loss: 1.1515 - acc: 0.5926 - val_loss: 1.0604 - val_acc: 0.6346\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 30s 755us/step - loss: 1.1051 - acc: 0.6094 - val_loss: 1.0262 - val_acc: 0.6446\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 30s 756us/step - loss: 1.0678 - acc: 0.6238 - val_loss: 1.0260 - val_acc: 0.6450\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 30s 757us/step - loss: 1.0383 - acc: 0.6363 - val_loss: 0.9933 - val_acc: 0.6495\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 30s 757us/step - loss: 1.0176 - acc: 0.6412 - val_loss: 0.9725 - val_acc: 0.6599\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 30s 757us/step - loss: 0.9868 - acc: 0.6537 - val_loss: 0.9694 - val_acc: 0.6574\n"
     ]
    }
   ],
   "source": [
    "cifar_history = cifar_model.fit(X_tr, Y_tr, \n",
    "               batch_size=128, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x15e59d30>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD7CAYAAABkO19ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBr1SSvm5/w/0WaZO4aivxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1adac748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cifar_result = DataFrame(cifar_history.history)\n",
    "cifar_result[['acc', 'val_acc']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,055,114\n",
      "Trainable params: 1,055,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cifar_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread, imresize, imsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mozzi = imread('data/mozzi.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = imresize(mozzi, (32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ..., \n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.imag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imsave('mozzi_32x32.png', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 32, 3)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5], dtype=int64)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_model.predict_classes(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = imread('bird.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = imresize(b, (32, 32))\n",
    "imsave('bird_32x32.png', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B = np.array([b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_model.predict_classes(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 239us/step\n",
      "Loss: 0.983, Acc.: 65.69%\n"
     ]
    }
   ],
   "source": [
    "print_score(cifar_model.evaluate(X_te, Y_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16, preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_model = VGG16(weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (Truncated file: eof = 431489024, sblock->base_addr = 0, stored_eoa = 553479920)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-5027ce7e5deb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvgg_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/vgg16_weights.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[0;32m   2636\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2637\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`load_weights` requires h5py.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2638\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'layer_names'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'model_weights'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2640\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (C:\\Minonda\\conda-bld\\h5py_1490029446037\\work\\h5py\\_objects.c:2867)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (C:\\Minonda\\conda-bld\\h5py_1490029446037\\work\\h5py\\_objects.c:2825)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open (C:\\Minonda\\conda-bld\\h5py_1490029446037\\work\\h5py\\h5f.c:2140)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (Truncated file: eof = 431489024, sblock->base_addr = 0, stored_eoa = 553479920)"
     ]
    }
   ],
   "source": [
    "vgg_model.load_weights('data/vgg16_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
